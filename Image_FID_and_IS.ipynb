{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwquVs+vGv3WudEoOwBAH0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import inception_v3\n",
        "from torchvision.transforms import functional as TF\n",
        "from scipy.linalg import sqrtm\n",
        "from PIL import Image\n",
        "from scipy.stats import entropy\n",
        "\n",
        "# Function to Image Preprocessing\n",
        "def preprocess_image(image_path, target_size=(299, 299)):\n",
        "    image = Image.open(image_path)\n",
        "    image = TF.resize(image, target_size)\n",
        "    image = TF.to_tensor(image)\n",
        "    if image.shape[0] == 1:  # If the image has a single channel (grayscale), convert it to RGB\n",
        "        image = image.expand(3, -1, -1)\n",
        "    image = TF.normalize(image, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Assuming normalization range is [-1, 1]\n",
        "    return image.unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "# Function to extract features from images using Inception-v3\n",
        "def extract_features(images):\n",
        "    inception_model = inception_v3(pretrained=True, progress=True, aux_logits=True)\n",
        "    inception_model.eval()\n",
        "    inception_model.to('cuda')  # Move the model to GPU if available\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        images = images.to('cuda') if torch.cuda.is_available() else images\n",
        "        features.append(inception_model(images)[0])\n",
        "    return torch.stack(features)\n",
        "\n",
        "\n",
        "# Function to calculate FID\n",
        "def calculate_fid(real_images, generated_images):\n",
        "    mu_real = torch.mean(real_images, dim=0)\n",
        "    mu_generated = torch.mean(generated_images, dim=0)\n",
        "    sigma_real = torch_cov(real_images)\n",
        "    sigma_generated = torch_cov(generated_images)\n",
        "\n",
        "    # Convert covariance matrices to numpy arrays\n",
        "    sigma_real_np = sigma_real.cpu().numpy()\n",
        "    sigma_generated_np = sigma_generated.cpu().numpy()\n",
        "\n",
        "    # Calculate FID\n",
        "    fid = torch.norm(mu_real - mu_generated) + torch.trace(torch.tensor(sqrtm(sigma_real_np @ sigma_generated_np)))\n",
        "    return fid.item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def torch_cov(m, rowvar=False):\n",
        "    if m.dim() < 2:\n",
        "        raise ValueError('m has less than 2 dimensions')\n",
        "\n",
        "    # Ensure that 'rowvar' is properly handled\n",
        "    if rowvar:\n",
        "        m = m.t()\n",
        "    if m.size(0) == 1:\n",
        "        return torch.zeros(m.size(1), m.size(1))  # Return tensor of zeros if there's only one sample\n",
        "\n",
        "    # Compute the covariance matrix\n",
        "    m -= torch.mean(m, dim=0, keepdim=True)\n",
        "    factor = 1 / (m.size(0) - 1)\n",
        "    cov_matrix = factor * m.t() @ m\n",
        "    return cov_matrix.unsqueeze(0) if cov_matrix.dim() == 2 else cov_matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load and preprocess real and generated images\n",
        "real_image_path = \"/content/sample_data/cat1.jpg\"\n",
        "generated_image_path = \"/content/sample_data/cat2.jpg\"\n",
        "\n",
        "real_image = preprocess_image(real_image_path)\n",
        "generated_image = preprocess_image(generated_image_path)\n",
        "\n",
        "# Extract features from images\n",
        "real_features = extract_features(real_image)\n",
        "generated_features = extract_features(generated_image)\n",
        "\n",
        "# Calculate FID\n",
        "fid_score = calculate_fid(real_features, generated_features)\n",
        "print(\"FID score:\", fid_score)\n"
      ],
      "metadata": {
        "id": "MaVarHXQJqnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy\n",
        "\n",
        "def inception_score(generated_images, num_splits=10):\n",
        "    inception_model = inception_v3(pretrained=True, progress=True, aux_logits=True)\n",
        "    inception_model.eval()\n",
        "    inception_model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    scores = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_splits):\n",
        "            preds = []\n",
        "            for i in range(0, generated_images.size(0), 32):\n",
        "                batch = generated_images[i:i+32].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "                pred = F.softmax(inception_model(batch), dim=1).cpu().numpy()\n",
        "                preds.append(pred)\n",
        "            preds = np.concatenate(preds, axis=0)\n",
        "            scores.append(entropy(np.mean(preds, axis=0), base=2))\n",
        "    return np.mean(scores), np.std(scores)\n",
        "\n",
        "# Assuming generated_images is a tensor of shape [batch_size, channels, height, width]\n",
        "\n",
        "# Calculate Inception Score\n",
        "is_mean, is_std = inception_score(generated_image)\n",
        "print(\"Inception Score (mean):\", is_mean)\n",
        "print(\"Inception Score (std):\", is_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeV5NrXuO6_4",
        "outputId": "cc7cada5-343e-48f6-a696-c142b775917d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inception Score (mean): 2.390452045766854\n",
            "Inception Score (std): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FOibO4olJ3Y2"
      }
    }
  ]
}